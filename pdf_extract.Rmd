---
title: "Extracting and Processing Property Information from PDFs"
output: 
  html_document: 
    code_folding: show
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(pdftools)
library(httr)
library(tidyverse)
library(rjson)
```

## Introduction

This document demonstrates how to extract text from a PDF document, process the extracted text using the OpenAI GPT-4 API, and format the extracted attributes into a structured JSON file. The process involves several steps, including loading necessary libraries, extracting text from PDFs, formatting the extracted text, sending it to the OpenAI API, parsing the response, and saving the results.

## Step 1: Extract Text from PDF

First, we load the necessary libraries and set the path to the PDF file. Then, we extract the text content from the PDF.

```{r load-libraries, message=FALSE}
# Load libraries
library(pdftools)
library(tidyverse)
```

```{r extract-text}
# Provide the path to the PDF file
pdf_file_path <- "https://stgendev01.blob.core.windows.net/python-test/nw1.pdf"

# Extract the text content from the PDF
text_content <- pdf_text(pdf_file_path)
```

## Step 2: Format Extracted Text for OpenAI API

We format the extracted text into JSON to prepare it for processing by the OpenAI API.

```{r format-text}
text_content_json <- rjson::toJSON(text_content)
```

## Step 3: Send Text to OpenAI API

We construct the request body and send it to the OpenAI API to extract structured information from the text.

```{r API_KEY, include=FALSE, eval=TRUE, echo=FALSE}
YOUR_API_KEY = "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"
```

```{r send-to-api, cache=TRUE}
url <- "https://api.openai.com/v1/chat/completions"


headers <- c(
  'Authorization' = paste('Bearer', YOUR_API_KEY),  # Replace YOUR_API_KEY with your actual key
  'Content-Type' = 'application/json'
)

body <- list(
  model = "gpt-4-1106-preview",
  messages = list(
    list(role = "system", content = "You are ChatGPT, a large language model trained by OpenAI."),
    list(role = "user", content = paste0("extract salient features of the property including the following for each property: Property:",
                                         "\n  - Address",
                                         "\n  - RentableArea",
                                         "\n  - NetOperatingIncome",
                                         "\n  - LandArea",
                                         "\n  - CapRate",
                                         "\n  - YearBuilt",
                                         "\n  - SalePrice",
                                         "\n  - Tenancy",
                                         "\n  - ExpirationDate",
                                         "\n  - TaxKey",
                                         "\n  - Taxes2021",
                                         "\n  - Municipality",
                                         "\n; as well as leasing details including:",
                                         "\n  - AnnualBaseRent",
                                         "\n  - CommonAreaMaintenance",
                                         "\n  - Insurance",
                                         "\n  - RealEstateTaxes",
                                         "\n  - ExpirationDate",
                                         "\n  - BaseRentIncrease",
                                         "\n  - Options",
                                         "\n  - Grantor",
                                         "\n and the Demographics as an Array for each Address",
                                         "\n from the pdf text below; DO NOT mention anything before and after the extracted data. just return the attributes in a format that I can easily parse to a structured JSON:\n", text_content_json))
  )
)

response <- POST(url, add_headers(.headers=headers), body = toJSON(body), encode = "json")
result <- content(response, as = "text", encoding = "UTF-8")
```

## Step 4: Parse API Response and Save as JSON

After receiving the response from the OpenAI API, we parse it and extract the relevant property information.

```{r parse-response, echo=TRUE, include=TRUE, results='asis'}
content <- content(response, "parsed")
prop_info <- content$choices[[1]]$message$content
cat(prop_info)
```

Finally, we save the extracted information as a JSON file.

```{r save-json}
jsonlite::write_json(prop_info, "output.json")
```

You can download the [extracted JSON file here](output.json).

## **Handling Scanned PDF Documents**

In this section, we process a PDF that is not based on text but rather on scanned images, such as photographs of documents. This requires a different approach from plain text extraction because we need to use Optical Character Recognition (OCR) to interpret the text from the images.

Similar to the previous section, we will use the **`pdftools`** library. However, since the PDF is more like a scanned picture, we will utilize the **`pdf_ocr_text`** function instead of **`pdf_text`** for text extraction:

```{r read-second-pdf}

# Provide the path to the PDF file
pdf_file_path2 <- "https://stgendev01.blob.core.windows.net/python-test/BOV.pdf"

# Extract the text content from the PDF using OCR
text_content2 <- pdftools::pdf_ocr_text(pdf_file_path2)
text_content_json2 <- rjson::toJSON(text_content2)
```

```{r send-to-api2, cache=TRUE}
body2 <- list(
  model = "gpt-4-1106-preview",
  messages = list(
    list(role = "system", content = "You are ChatGPT, a large language model trained by OpenAI."),
    list(role = "user", content = paste0("extract salient features of the property including the following for each property: Property:",
                                         "\n  - Address",
                                         "\n  - RentableArea",
                                         "\n  - NetOperatingIncome",
                                         "\n  - LandArea",
                                         "\n  - CapRate",
                                         "\n  - YearBuilt",
                                         "\n  - SalePrice",
                                         "\n  - Tenancy",
                                         "\n  - ExpirationDate",
                                         "\n  - TaxKey",
                                         "\n  - Taxes2021",
                                         "\n  - Municipality",
                                         "\n; as well as leasing details including:",
                                         "\n  - AnnualBaseRent",
                                         "\n  - CommonAreaMaintenance",
                                         "\n  - Insurance",
                                         "\n  - RealEstateTaxes",
                                         "\n  - ExpirationDate",
                                         "\n  - BaseRentIncrease",
                                         "\n  - Options",
                                         "\n  - Grantor",
                                         "\n and the Demographics as an Array for each Address",
                                         "\n from the pdf text below; DO NOT mention anything before and after the extracted data. just return the attributes in a format that I can easily parse to a structured JSON:\n", text_content_json2))
  )
)

response2 <- POST(url, add_headers(.headers=headers), body = toJSON(body2), encode = "json")
result2 <- content(response2, as = "text", encoding = "UTF-8")
```

```{r parse-response2, echo=TRUE, include=TRUE, results='asis'}
content2 <- content(response2, "parsed")
prop_info2 = content2$choices[[1]]$message$content
cat(prop_info2)
```

Finally, we save the extracted information as a JSON file.

```{r save-json2}
jsonlite::write_json(prop_info2, "output2.json")
```

You can download the [extracted JSON file](output2.json) of the second property.


## Conclusion

This R Markdown document demonstrated how to extract text from a PDF, process it with the OpenAI GPT-4 API, and save the processed information as a JSON file. By structuring unstructured data into a more digestible format, we can more easily analyze and utilize the information.
